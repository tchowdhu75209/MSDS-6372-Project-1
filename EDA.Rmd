---
title: "EDA"
author: "Team_1"
date: "5/29/2020"
output: html_document 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Package Mang, echo=FALSE}
# Install/Import Packages
install.packages("naniar")
install.packages("corrplot")
install.packages("funModeling")
install.packages("tidyverse")
install.packages("Hmisc")
install.packages("mice")
install.packages("glmnet")
install.packages("mltools")


library(naniar)
library(ggplot2)
library(corrplot)
library(dplyr)
library(caret)
library(funModeling)
library(tidyverse) 
library(Hmisc)
library(mice)
library(randomForest)
library(glmnet)
library(data.table)
library(Matrix)
library(caret)
library(mltools)

```

```{r Import, echo=FALSE}
# Import Data Sets
moddata = read.csv("modelingData.csv", header = TRUE)
projdata = read.csv("projectionData.csv", header = TRUE)

##Training Dataset modified with TimeStamp (month, day, year, monthyear)
trainTSdata = read.csv("train_TimeStamp.csv", header = TRUE)

# Identify Structure and Stats
summary(moddata)
str(moddata)
summary(projdata)
str(projdata)

## Writing data out to Excel File
install.packages("writexl")
library(writexl)
write_xlsx(x = train_df_IQR, path = "train_df.xlsx", col_names = TRUE)
write_xlsx(x = test_df_IQR, path = "test_df.xlsx", col_names = TRUE)

##Aggregate Trainimg Dataset by MonthYear for Goal #2
trainTSdata = aggregate(trainTSdata$price_doc,
               list(time = trainTSdata$monthyear),
               mean)
write_xlsx(x = trainTSdata, path = "aggdataList.xlsx", col_names = TRUE)
head((trainTSdata))


```

Data Cleaning and Wrangling
```{r Data Wrangling, echo=FALSE}
# Data Cleaning / Wrangling (any renaming of variables or standardizing of values.)
# Imputation Using Multivariate Imputation by Chained Equation (MICE)

# Impute Missing Values
moddata_imp = mice(moddata, m=5, maxit=5, method='cart', seed = 500)
moddata_imp2 <- complete(moddata_imp, "long", inc = TRUE)

projdata_imp = mice(projdata, m=5, maxit=5, method='cart', seed = 500)
projdata_imp2 = complete(projdata_imp, "long", inc = TRUE)

train_df = moddata_imp2 %>% filter(.imp == 5)
test_df = projdata_imp2 %>% filter(.imp == 5)

train_df <- na.omit(train_df)
test_df <- na.omit(test_df)


```

Exploratory Data Analysis
```{r Outlier, echo=FALSE}
# Outlier Identification and Handling
outlierTreament<-function(x){
  qnt <- quantile(x, probs=c(.25, .75), na.rm = T)
  caps <- quantile(x, probs=c(.05, .95), na.rm = T)
  H <- 1.5 * IQR(x, na.rm = T)
  x[x < (qnt[1] - H)] <- caps[1]
  x[x > (qnt[2] + H)] <- caps[2]
  return(x)}

# Remove String Columns 
numeric_cols<-test_df[sapply(test_df, is.numeric)]
numeric_data<-test_df[,test_df%in%numeric_cols]

numeric_cols2<-train_df[sapply(train_df, is.numeric)]
numeric_data2<-train_df[,train_df%in%numeric_cols2]

# Apply Outlier/IQR Functions to DBs
test_df_IQR<-as.data.frame(sapply(numeric_data,outlierTreament))
train_df_IQR<-as.data.frame(sapply(numeric_data2,outlierTreament))

summary(test_df_IQR)
summary(train_df_IQR)




```

```{r Miss Value, echo=FALSE}
# Missing value identification, summary and possible imputation (mean, median, regression.) This may also be considered part of “Data Wrangling”.

#Create plots to analyize missing data
gg_miss_var(train_df_IQR)
vis_miss(train_df_IQR, warn_large_data = FALSE)
gg_miss_var(train_df_IQR)
vis_miss(train_df_IQR, warn_large_data = FALSE)
```

```{r}

############################################
#basic plots to analyize data
############################################

# Plot to show the count by Product_type (Investment vs OwnerOccupie)
prodCount <- moddata %>%
  group_by(product_type) %>%
  summarise(counts = n())

ggplot(prodCount, aes(x = product_type, y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity") +
  geom_text(aes(label = counts), vjust = -0.3) + 
  theme_grey()

#PLot Price_doc vs full_sq
ggplot(aes(x=full_sq, y=price_doc), data=train_df) + 
    geom_point(color='blue')+geom_smooth()


# % of missed data by features
miss_pct <- map_dbl(train_df_IQR, function(x) { round((sum(is.na(x)) / length(x)) * 100, 1) })
miss_pct <- miss_pct[miss_pct > 0]
data.frame(miss=miss_pct, var=names(miss_pct), row.names=NULL) %>%
    ggplot(aes(x=reorder(var, -miss), y=miss)) + 
    geom_bar(stat='identity', fill='blue') +
    labs(x='', y='% missing', title='Percent missing data by feature') +
    theme(axis.text.x=element_text(angle=90, hjust=1))

# Histogram showing build year distribution
train_df_IQR %>% 
    filter(build_year > 1940 & build_year < 2018) %>%
    ggplot(aes(x=build_year)) + 
    geom_histogram(fill='blue') + 
    ggtitle('Distribution of build year')

table(train_df_IQR$build_year)

```

```{r Multicollinearity, echo=FALSE}
# Multicollinearity (is there reason to believe it is present?)  You don’t have to address every potential pair of variables that may be collinear.  Just provide a plot and or other evidence of a single occurrence of multicollinearity if at least one exists and then mention possible other occurrences.  

#Return numeric values only
df_numeric <- train_df_IQR[, sapply(train_df_IQR, is.numeric)]

#Correlation Plot
df_numeric <-select(train_df_IQR, -.imp)
df_numeric[is.na(df_numeric)] <- "0"
df_numeric <- df_numeric[, sapply(df_numeric, is.numeric)]
df_corr <- round(cor(df_numeric),2)

corrplot(cor(df_corr), diag = FALSE, order = "FPC",
         tl.pos = "td", tl.cex = 0.5, method = "color", type = "upper")

```

